{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CVAT Video annotations to AVA format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip File\n",
    "Make sure to set \"path_to_zip\" as the path to the zip file exported from CVAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(path_to_zip, extract_to=\"./\"):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(path_to_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "path_to_zip = \"./Escape_Room_Small.zip\"\n",
    "unzip_file(path_to_zip, extract_to=\"./\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After unzipping, you should have a file named \"annotations.xml\". Make sure to rename this to something appropriate and set it below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup\n",
    "Make sure to set `PATH_TO_XML`, `SAVE_FILE_PATH`  \n",
    "`NAME_TO_ID` maps the names of the actions to the id as described in `Action_Detection/data/actions_list.txt`  \n",
    "You can adjust this if you need to but it must be consistent with the `actions_list.txt`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import xmltodict\n",
    "import pprint\n",
    "\n",
    "cores = os.cpu_count()\n",
    "print(f\"Number of cores: {cores}\")\n",
    "\n",
    "\n",
    "PATH_TO_XML = \"./escape_room_small_annotations.xml\" #### SET XML FILE PATH HERE\n",
    "SAVE_FILE_PATH = \"./ava_annotations.txt\" #### SET SAVE FILE PATH HERE FOR THE CONVERTED ANNOTATIONS\n",
    "NAME_TO_ID = {\n",
    "    \"walk\": 0,\n",
    "    \"sit\": 1,\n",
    "    \"stand\": 2,\n",
    "    \"bend/bow (at the waist)\": 3,\n",
    "    \"run/jog\": 4,\n",
    "    \"hand wave\": 5,\n",
    "    \"get up\": 6,\n",
    "    \"paired(standing together with one other person)\": 7,\n",
    "    \"huddle (standing together with 2 or more people)\": 8,\n",
    "    \"lift/pick up\": 9,\n",
    "    \"carry/hold (an object)\": 10,\n",
    "    \"point to (an object)\": 11,\n",
    "    \"write\": 12,\n",
    "    \"read\": 13,\n",
    "    \"put down\": 14,\n",
    "    \"watch (object)\": 15,\n",
    "    \"talk to\": 16,\n",
    "    \"listen\": 17,\n",
    "    \"watch (person)\": 18,\n",
    "    \"gesture (a person)\": 19,\n",
    "    \"give/serve (an object) to (a person)\": 20,\n",
    "    \"take (an object) from (a person)\": 21,\n",
    "    \"face to face\": 22,\n",
    "    \"hi 5\": 23,\n",
    "    \"laugh\":25,\n",
    "    \"smile\":26,\n",
    "    \"stressed\":27,\n",
    "    \"annoyed/frustrated\":28,\n",
    "    \"take (an object) from (robot)\":29,\n",
    "    \"give/serve (an object) to (robot)\":30,\n",
    "    \"talk to (robot)\":31,\n",
    "    \"listen to (robot)\":32,\n",
    "    \"watch (robot)\":33,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert annotations to AVA format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_dic(xml_path):\n",
    "    with open(xml_path) as fd:\n",
    "        dic = xmltodict.parse(fd.read())\n",
    "    return dic\n",
    "\n",
    "\n",
    "annotations = get_xml_dic(PATH_TO_XML)['annotations']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos:  2\n",
      "height:  360\n",
      "width:  640\n",
      "tracks:  6\n"
     ]
    }
   ],
   "source": [
    "video_name_to_task_id = {}\n",
    "task_id_to_video_name = {}\n",
    "height = None\n",
    "width = None\n",
    "\n",
    "\n",
    "for task in annotations['meta']['project']['tasks']['task']:\n",
    "    task_id = int(task['id'])\n",
    "    video_name = task['name']\n",
    "    video_name_to_task_id[video_name] = task_id\n",
    "    task_id_to_video_name[task_id] = video_name\n",
    "    height = int(task['original_size']['height'])\n",
    "    width = int(task['original_size']['width'])\n",
    "\n",
    "print(\"Number of videos: \", len(video_name_to_task_id))\n",
    "assert height is not None and width is not None\n",
    "print(\"height: \", height)\n",
    "print(\"width: \", width)\n",
    "print(\"tracks: \", len(annotations['track']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open(SAVE_FILE_PATH, \"w\") as f:\n",
    "\n",
    "\n",
    "    for track in annotations['track']:\n",
    "        track_id = track['@id']\n",
    "        video_name = task_id_to_video_name[int(track['@task_id'])]\n",
    "        for box in track['box']:\n",
    "            frame_num = int(box[\"@frame\"])\n",
    "            if frame_num%30 == 0 and frame_num != 0:\n",
    "                outside = False if box['@outside'] == '0' else True\n",
    "                if not outside:\n",
    "                    xtl = round(float(box['@xtl']) / width, 3)\n",
    "                    ytl = round(float(box['@ytl']) / height, 3)\n",
    "                    xbr = round(float(box['@xbr']) / width, 3)\n",
    "                    ybr = round(float(box['@ybr']) / height, 3)\n",
    "                    for attribute in box['attribute']:\n",
    "                        action_name = attribute['#text']\n",
    "                        if action_name != \"None\" and attribute['@name'] != \"Person ID\":\n",
    "                            action_id = NAME_TO_ID[action_name]\n",
    "                            row_str = f\"{video_name},{frame_num},{xtl},{ytl},{xbr},{ybr},{action_id},{track_id}\"\n",
    "                            f.write(row_str + \"\\n\")\n",
    "            \n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Frames\n",
    "We need to extract frames from all the videos. You can use the following script to extract frames and place them in the proper AVA format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "video_folder = \"./all_videos\"\n",
    "video_paths = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/exouser/miniconda3/envs/py310/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/exouser/miniconda3/envs/py310/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted frames from G3_hazard_segment1\n",
      "Extracted frames from G3_hazard_segment7\n",
      "Extracted frames from G1_medical_segment3\n",
      "Extracted frames from G1_medical_segment1\n",
      "Extracted frames from G5_hazard_segment5\n",
      "Extracted frames from G5_hazard_segment3\n",
      "Extracted frames from G2_medical_segment6\n",
      "Extracted frames from G1_medical_segment9\n",
      "Extracted frames from G1_medical_segment4\n",
      "Extracted frames from G2_medical_segment7\n",
      "Extracted frames from G2_medical_segment9\n",
      "Extracted frames from G1_medical_segment7\n",
      "Extracted frames from G2_medical_segment2\n",
      "Extracted frames from G5_medical_segment6\n",
      "Extracted frames from G5_medical_segment1\n",
      "Extracted frames from G2_hazard_segment7\n",
      "Extracted frames from G5_medical_segment7\n",
      "Extracted frames from G5_medical_segment4\n",
      "Extracted frames from G4_hazard_segment2\n",
      "Extracted frames from G1_hazard_segment8\n",
      "Extracted frames from G4_hazard_segment9\n",
      "Extracted frames from G4_hazard_segment4\n",
      "Extracted frames from G1_hazard_segment6\n",
      "Extracted frames from G2_hazard_segment2\n",
      "Extracted frames from G1_hazard_segment7\n",
      "Extracted frames from G1_hazard_segment10\n",
      "Extracted frames from G3_medical_segment1\n",
      "Extracted frames from G1_hazard_segment9\n",
      "Extracted frames from G5_medical_segment10\n",
      "Extracted frames from G3_medical_segment9\n",
      "Extracted frames from G3_medical_segment2\n",
      "Extracted frames from G3_medical_segment8\n",
      "Extracted frames from G3_hazard_segment8\n",
      "Extracted frames from G3_hazard_segment4\n",
      "Extracted frames from G3_hazard_segment6\n",
      "Extracted frames from G5_medical_segment3\n",
      "Extracted frames from G2_hazard_segment4\n",
      "Extracted frames from G3_hazard_segment5\n",
      "Extracted frames from G3_hazard_segment9\n",
      "Extracted frames from G4_medical_segment8\n",
      "Extracted frames from G5_hazard_segment9\n",
      "Extracted frames from G5_hazard_segment1\n",
      "Extracted frames from G1_medical_segment5\n",
      "Extracted frames from G1_medical_segment6\n",
      "Extracted frames from G1_hazard_segment5\n",
      "Extracted frames from G2_medical_segment4\n",
      "Extracted frames from G2_hazard_segment5\n",
      "Extracted frames from G1_hazard_segment2\n",
      "Extracted frames from G2_hazard_segment10\n",
      "Extracted frames from G1_medical_segment2\n",
      "Extracted frames from G1_hazard_segment3\n",
      "Extracted frames from G5_hazard_segment4\n",
      "Extracted frames from G2_hazard_segment6\n",
      "Extracted frames from G2_hazard_segment1\n",
      "Extracted frames from G1_hazard_segment4\n",
      "Extracted frames from G4_hazard_segment3\n",
      "Extracted frames from G2_hazard_segment3\n",
      "Extracted frames from G4_medical_segment10\n",
      "Extracted frames from G4_hazard_segment6\n",
      "Extracted frames from G4_hazard_segment1\n",
      "Extracted frames from G4_medical_segment6\n",
      "Extracted frames from G3_medical_segment3\n",
      "Extracted frames from G3_medical_segment6\n",
      "Extracted frames from G2_medical_segment1\n",
      "Extracted frames from G3_medical_segment10\n",
      "Extracted frames from G5_hazard_segment10\n",
      "Extracted frames from G4_medical_segment5\n",
      "Extracted frames from G3_hazard_segment10\n",
      "Extracted frames from G5_hazard_segment7\n",
      "Extracted frames from G4_medical_segment2\n",
      "Extracted frames from G5_hazard_segment8\n",
      "Extracted frames from G4_medical_segment3\n",
      "Extracted frames from G4_hazard_segment10\n",
      "Extracted frames from G5_medical_segment5\n",
      "Extracted frames from G3_hazard_segment3\n",
      "Extracted frames from G3_hazard_segment2\n",
      "Extracted frames from G2_medical_segment8\n",
      "Extracted frames from G2_medical_segment5\n",
      "Extracted frames from G4_medical_segment7\n",
      "Extracted frames from G5_hazard_segment2\n",
      "Extracted frames from G1_medical_segment8\n",
      "Extracted frames from G4_medical_segment4\n",
      "Extracted frames from G5_medical_segment8\n",
      "Extracted frames from G4_hazard_segment5\n",
      "Extracted frames from G5_medical_segment2\n",
      "Extracted frames from G4_hazard_segment7\n",
      "Extracted frames from G5_medical_segment9\n",
      "Extracted frames from G4_medical_segment1\n",
      "Extracted frames from G4_hazard_segment8\n",
      "Extracted frames from G2_medical_segment3\n",
      "Extracted frames from G5_hazard_segment6\n",
      "Extracted frames from G3_medical_segment4\n",
      "Extracted frames from G3_medical_segment7\n",
      "Extracted frames from G2_medical_segment10\n",
      "Extracted frames from G4_medical_segment9\n",
      "Extracted frames from G1_hazard_segment1\n",
      "Extracted frames from G2_hazard_segment8\n",
      "Extracted frames from G1_medical_segment10\n",
      "Extracted frames from G2_hazard_segment9\n",
      "Extracted frames from G3_medical_segment5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import multiprocessing\n",
    "\n",
    "# Listen up, we got our folders here\n",
    "video_folder = 'all_videos'\n",
    "output_folder = 'frames'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    video_output_folder = os.path.join(output_folder, video_name)\n",
    "    os.makedirs(video_output_folder, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        frame_filename = f\"{video_name}_{frame_count:06d}.jpg\"\n",
    "        frame_filepath = os.path.join(video_output_folder, frame_filename)\n",
    "        cv2.imwrite(frame_filepath, frame)\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted frames from {video_name}\")\n",
    "\n",
    "# Get the video paths\n",
    "video_paths = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
    "\n",
    "# Process the videos\n",
    "def process_video(video_path):\n",
    "    extract_frames(video_path, output_folder)\n",
    "\n",
    "with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    pool.map(process_video, video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create file listing all of the frames used for validation and for test\n",
    "import pandas as pd\n",
    "file_path = SAVE_FILE_PATH\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "video_names = df[0].unique()\n",
    "print(video_names)\n",
    "print(\"Number of videos: \", len(video_names))\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(video_names)\n",
    "split_index = int(0.8 * len(video_names))\n",
    "train_set = video_names[:split_index]\n",
    "val_set = video_names[split_index:]\n",
    "\n",
    "print(\"Number of videos in train set: \", len(train_set))\n",
    "print(\"Number of videos in val set: \", len(val_set))\n",
    "\n",
    "\n",
    "os.makedirs(\"./frame_lists\", exist_ok=True)\n",
    "val_file = \"./frame_lists/val.csv\"\n",
    "train_file = \"./frame_lists/train.csv\"\n",
    "\n",
    "video_id = 0\n",
    "val_lines = []\n",
    "train_lines = []\n",
    "\n",
    "for video_name in val_set:\n",
    "    frames_folder_path = os.path.join(\"./frames\", video_name.split(\".\")[0])\n",
    "    frames = os.listdir(frames_folder_path)\n",
    "    frames.sort(key=lambda x: int(x.split(\".\")[0].split(\"_\")[-1]))\n",
    "    for frame in frames:\n",
    "        frame_path = os.path.join(frames_folder_path, frame)\n",
    "        frame_num = int(frame.split(\".\")[0].split(\"_\")[-1])\n",
    "        frame_path = os.path.join(os.path.basename(os.path.dirname(frame_path)), os.path.basename(frame_path))\n",
    "\n",
    "        line = f\"{video_id} {video_id} {frame_num-1} {frame_path} \\\"\\\"\"\n",
    "        val_lines.append(line)\n",
    "    video_id += 1\n",
    "\n",
    "for video_name in train_set:\n",
    "    frames_folder_path = os.path.join(\"./frames\", video_name.split(\".\")[0])\n",
    "    frames = os.listdir(frames_folder_path)\n",
    "    frames.sort(key=lambda x: int(x.split(\".\")[0].split(\"_\")[-1]))\n",
    "    for frame in frames:\n",
    "        frame_path = os.path.join(frames_folder_path, frame)\n",
    "        frame_num = int(frame.split(\".\")[0].split(\"_\")[-1])\n",
    "        frame_path = os.path.join(os.path.basename(os.path.dirname(frame_path)), os.path.basename(frame_path))\n",
    "\n",
    "        line = f\"{video_id} {video_id} {frame_num-1} {frame_path} \\\"\\\"\"\n",
    "        train_lines.append(line)\n",
    "    video_id += 1\n",
    "\n",
    "with open(val_file, \"w\") as f:\n",
    "    f.write(\"original_vido_id video_id frame_id path labels\\n\")\n",
    "    for line in val_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(train_file, \"w\") as f:\n",
    "    f.write(\"original_vido_id video_id frame_id path labels\\n\")\n",
    "    for line in train_lines:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
